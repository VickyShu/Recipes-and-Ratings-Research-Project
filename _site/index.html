<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Recipes and Ratings Research Project | Recipes-and-Ratings-Research-Project</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Recipes and Ratings Research Project" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Recipes-and-Ratings-Research-Project" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Recipes and Ratings Research Project" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"Recipes and Ratings Research Project","name":"Recipes-and-Ratings-Research-Project","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=f1a8b06a5a76bf7a479493255eacb1f83c17509c">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Recipes and Ratings Research Project</h1>
      <h2 class="project-tagline"></h2>
      
        <a href="https://github.com/VickyShu/Recipes-and-Ratings-Research-Project" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="recipes-and-ratings-research-project">Recipes and Ratings Research Project</h1>

<p><strong>Authors</strong>: Xin Shu, Chang Shu</p>

<h2 id="project-overview">Project Overview</h2>
<p>This project aims to explore the potential correlation between the calorie content of recipes and the ratings giving by people and to predict that ratings based on several features. This is a project for DSC80 at UCSD. The dataset used to investigate this topic can be find <a href="https://drive.google.com/file/d/1kIbMz6jlhleiZ9_3QthmUnifoSds_2EI/view">here</a>.</p>

<h2 id="introduction">Introduction</h2>
<p>In the culinary world, the balance between taste and health is a subject of much interest and debate. Calorie content, a measure of energy intake, is a critical factor in this balance, directly affecting an individual’s health and well-being. High-calorie recipes are often associated with comfort and indulgence, potentially leading to higher ratings due to satisfaction and taste. In this project, we aim to examine the relationship between recipe ratings and calorie content to reveal the preferences and trends that drive our dietary habits. However, nowadays, the modern health movement encourages lower-calorie options to combat the rising tide of lifestyle-related illnesses. Thus, exploring this relationship is not just an academic exercise, which is also a way to combine culinary arts with nutritional science for a healthier society.</p>

<h3 id="introduction-to-datasets">Introduction to Datasets</h3>
<p>Our two datasets comprise detailed records from a popular cooking website, capturing the essence of what makes a recipe resonate with their audience. Within these two datasets, we are trying to answer a question: Is there a relationship between the calorie content of a recipe and its user rating?</p>

<p>The “RAW_recipes” dataset consists of 83,782 rows, each row representing a unique recipe. There are ten columns in RAW_recipes. Relevant columns in this dataset include:</p>

<table>
  <thead>
    <tr>
      <th>Column</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>‘name’</td>
      <td>Recipe name</td>
    </tr>
    <tr>
      <td>‘id’</td>
      <td>Recipe ID</td>
    </tr>
    <tr>
      <td>‘minutes’</td>
      <td>Minutes to prepare recipe</td>
    </tr>
    <tr>
      <td>‘contributor_id’</td>
      <td>User ID who submitted this recipe</td>
    </tr>
    <tr>
      <td>‘submitted’</td>
      <td>Date recipe was submitted</td>
    </tr>
    <tr>
      <td>‘tags’</td>
      <td>Food.com tags for recipe</td>
    </tr>
    <tr>
      <td>‘nutrition’</td>
      <td>Nutrition information in the form [calories (#), total fat (PDV), sugar (PDV), sodium (PDV), protein (PDV), saturated fat (PDV), carbohydrates (PDV)]; PDV stands for “percentage of daily value”</td>
    </tr>
    <tr>
      <td>‘n_steps’</td>
      <td>Number of steps in recipe</td>
    </tr>
    <tr>
      <td>‘steps’</td>
      <td>Text for recipe steps, in order</td>
    </tr>
    <tr>
      <td>‘description’</td>
      <td>User-provided description</td>
    </tr>
  </tbody>
</table>

<p>The “RAW_interactions” dataset is considerably larger, with 731,927 rows. This dataset contains the following columns relevant to our question:</p>

<table>
  <thead>
    <tr>
      <th>Column</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>‘user_id’</td>
      <td>User ID</td>
    </tr>
    <tr>
      <td>‘recipe_id’</td>
      <td>Recipe ID</td>
    </tr>
    <tr>
      <td>‘date’</td>
      <td>Date of interaction</td>
    </tr>
    <tr>
      <td>‘rating’</td>
      <td>Rating given</td>
    </tr>
    <tr>
      <td>‘review’</td>
      <td>Review text</td>
    </tr>
  </tbody>
</table>

<p>For our investigation into the connection between recipe ratings and calorie content, we use some specific columns from two datasets. From the first dataset, “RAW_recipes,” we concentrated on the <code class="language-plaintext highlighter-rouge">nutrition</code> column, which lists critical nutritional values such as calories, total fat, sugar, protein, saturated fat, and carbohydrates. We will extract the calorie content, creating a new column named <code class="language-plaintext highlighter-rouge">calories (#)</code>. This new column will be the cornerstone of our study as it provides a direct measure of the energy content in each recipe.</p>

<p>We turned to the <code class="language-plaintext highlighter-rouge">rating</code> column from the second dataset, “RAW_interactions”. This column could reveal whether there is a preference trend towards higher or lower-calorie dishes when analyzed with the calorie information.</p>

<hr />

<h2 id="cleaning-and-eda">Cleaning and EDA</h2>
<h3 id="data-cleaning">Data Cleaning</h3>
<p>Before conducting the analysis based on these two datasets, we follow the following steps to clean the datasets:</p>

<ol>
  <li>
    <p><strong>Left merge the recipes and interactions datasets together:</strong> We combine the recipes and ratings datasets using a <code class="language-plaintext highlighter-rouge">left</code> merge based on <code class="language-plaintext highlighter-rouge">id</code> and <code class="language-plaintext highlighter-rouge">recipe_id</code>. This is done to ensure all recipes are included in our analysis.</p>
  </li>
  <li>
    <p><strong>Fill all ratings of 0 with <code class="language-plaintext highlighter-rouge">np.nan</code>:</strong> In the merged dataset, we convert all ratings of 0 to N/A. This is reasonable since the rationale that a rating of 0 could potentially represent cases where a rating was not given, rather than a deliberate rating of zero. Rating scales typically start from 1, and a 0 is often not a selectable option for users. Thus, a 0 could be replaced by N/A for missing or unreported ratings.</p>
  </li>
  <li>
    <p><strong>Calculating average rating:</strong> After addressing the zero ratings and merging two datasets, we calculate the average rating for each recipe by add a new column <code class="language-plaintext highlighter-rouge">average_rating</code>.</p>
  </li>
  <li>
    <p><strong>Converting <code class="language-plaintext highlighter-rouge">nutrition</code> data from string to a list of floats and assign to individual columns:</strong> The <code class="language-plaintext highlighter-rouge">nutrition</code> column looks like a list but is actually a text string. We convert this string into a list of floats and create separate columns for each nutrient - <code class="language-plaintext highlighter-rouge">"[calories (#), total fat (PDV), sugar (PDV), sodium (PDV), protein (PDV), saturated fat (PDV), carbohydrates (PDV)]"</code> - to make the data clear and ready for analysis.</p>
  </li>
</ol>

<p>The cleaned dataframe is shown below (with only relevant columns).</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">name</th>
      <th style="text-align: right">id</th>
      <th style="text-align: right">n_steps</th>
      <th style="text-align: left">steps</th>
      <th style="text-align: left">ingredients</th>
      <th style="text-align: right">n_ingredients</th>
      <th style="text-align: right">calories</th>
      <th style="text-align: right">ratings</th>
      <th style="text-align: right">minutes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1 brownies in the world best ever</td>
      <td style="text-align: right">333281</td>
      <td style="text-align: right">10</td>
      <td style="text-align: left">[‘heat the oven to 350f and arrange the rack in the middle’, …]</td>
      <td style="text-align: left">[‘bittersweet chocolate’, …]</td>
      <td style="text-align: right">9</td>
      <td style="text-align: right">138.4</td>
      <td style="text-align: right">4.0</td>
      <td style="text-align: right">40</td>
    </tr>
    <tr>
      <td style="text-align: left">1 in canada chocolate chip cookies</td>
      <td style="text-align: right">453467</td>
      <td style="text-align: right">12</td>
      <td style="text-align: left">[‘pre-heat oven the 350 degrees f’, …]</td>
      <td style="text-align: left">[‘white sugar’, ‘brown sugar’, …]</td>
      <td style="text-align: right">11</td>
      <td style="text-align: right">595.1</td>
      <td style="text-align: right">5.0</td>
      <td style="text-align: right">45</td>
    </tr>
    <tr>
      <td style="text-align: left">412 broccoli casserole</td>
      <td style="text-align: right">306168</td>
      <td style="text-align: right">6</td>
      <td style="text-align: left">[‘preheat oven to 350 degrees’, …]</td>
      <td style="text-align: left">[‘frozen broccoli cuts’, …]</td>
      <td style="text-align: right">9</td>
      <td style="text-align: right">194.8</td>
      <td style="text-align: right">5.0</td>
      <td style="text-align: right">40</td>
    </tr>
    <tr>
      <td style="text-align: left">412 broccoli casserole</td>
      <td style="text-align: right">306168</td>
      <td style="text-align: right">6</td>
      <td style="text-align: left">[‘preheat oven to 350 degrees’, …]</td>
      <td style="text-align: left">[‘frozen broccoli cuts’, …]</td>
      <td style="text-align: right">9</td>
      <td style="text-align: right">194.8</td>
      <td style="text-align: right">5.0</td>
      <td style="text-align: right">40</td>
    </tr>
    <tr>
      <td style="text-align: left">412 broccoli casserole</td>
      <td style="text-align: right">306168</td>
      <td style="text-align: right">6</td>
      <td style="text-align: left">[‘preheat oven to 350 degrees’, …]</td>
      <td style="text-align: left">[‘frozen broccoli cuts’, …]</td>
      <td style="text-align: right">9</td>
      <td style="text-align: right">194.8</td>
      <td style="text-align: right">5.0</td>
      <td style="text-align: right">40</td>
    </tr>
  </tbody>
</table>

<p>The type of each columns in the cleaned dataframe is shown below:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name              object
id                 int64
n_steps            int64
steps             object
ingredients       object
n_ingredients      int64
calories (#)     float64
rating           float64
minutes            int64
dtype: object
</code></pre></div></div>
<h3 id="univariate-analysis">Univariate Analysis</h3>
<p>In the univariate analysis section, we will analyze the distribution of rating scale and the distribution of calories.</p>
<h4 id="distribution-of-ratings-scale">Distribution of Ratings Scale</h4>
<iframe src="assets/rating.html" width="800" height="600" frameborder="0"></iframe>
<p>The plot displays a bar chart that illustrates the distribution of ratings on a 1-5 scale. The x-axis represents the rating scale with values from 1 to 5. The y-axis represents the count of ratings for each recipe.</p>

<p>The chart shows a clear trend: the highest rating (5) has been given significantly more often than the lower ratings of 1 through 4. This could suggest that users tend to favor recipes with higher ratings, or it could indicate that there is a positive skew in user behavior, where users are more likely to rate a recipe if they found it very satisfactory (rating of 5).</p>

<h4 id="distribution-of-calories">Distribution of calories</h4>
<iframe src="assets/calories.html" width="800" height="600" frameborder="0"></iframe>

<p>The histogram shows the distribution of calories for a collection of recipes, with the data filtered to exclude the top 1% of recipes with the highest calorie content.</p>

<p>From the histogram, we can observe the following:</p>

<p><strong>Skewed Distribution:</strong> The distribution of calories is right-skewed, meaning there are more recipes with lower calorie content and fewer recipes with higher calorie content.</p>

<p><strong>Most Common Range:</strong> The majority of the recipes appear to fall within the lower calorie range, with a steep drop-off as calorie content increases.</p>

<p><strong>High-Calorie Recipes:</strong> While there are recipes with higher calorie counts, they are significantly less common, as evidenced by the long tail extending to the right of the histogram.</p>

<h3 id="bivariate-analysis">Bivariate Analysis</h3>
<p>To do the Bivariate Analysis, we will use a scatter plot to illustrate the relationship between the calorie content of recipes and the number of steps in recipe and use a boxplot to illustrate the relationship between the calorie content of recipes and the ratings giving by people.</p>

<h4 id="distribution-of-scatter-plot-for-calories-and-the-number-of-steps">Distribution of scatter plot for calories and the number of steps</h4>
<iframe src="assets/scatter.html" width="800" height="600" frameborder="0"></iframe>
<p>From this visualization, it is observed that there is no strong correlation between calories and the number of steps. We could say that there is a weak relationship between the calorie content of recipes and the number of steps.</p>

<h4 id="distribution-of-box-plot-for-calories-and-ratings">Distribution of box plot for calories and ratings</h4>
<iframe src="assets/boxplot.html" width="800" height="600" frameborder="0"></iframe>
<p>This box plot displays the distribution of calorie content across different recipe ratings from 1 to 5.</p>

<p>The <strong>median calorie content</strong> appears relatively consistent across ratings, suggesting that the central tendency of calories is not strongly affected by how users rate the recipes.</p>

<p>The <strong>range and interquartile range (IQR)</strong> of calories seem similar across ratings, indicating that there is a similar variation in calorie content regardless of the rating.</p>

<p>Thus, from this plot, we cannot conclude anything about the relationship between the calories and ratings, as the central tendencies and spreads are similar across all rating categories.</p>

<h3 id="interesting-aggregates">Interesting Aggregates</h3>
<p>In the aggregates analysis, we will study the calories content.</p>

<p>The pivot table summarizes the calorie content of recipes by their user ratings. Each row corresponds to a rating value, with the following statistical measures:</p>

<p><strong>Mean:</strong> The average calorie content for recipes with that rating.</p>

<p><strong>Median:</strong> The middle value in the range of calorie contents for recipes with that rating.</p>

<p><strong>Standard Deviation (std):</strong> A measure of the variation of the calorie amounts from the mean for recipes with that rating.</p>

<p><strong>Maximum (max):</strong> The highest calorie content found in recipes for each rating category.</p>

<table>
  <thead>
    <tr>
      <th>rating</th>
      <th>mean</th>
      <th>median</th>
      <th>std</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.0</td>
      <td>486.595401</td>
      <td>316.0</td>
      <td>757.480650</td>
      <td>17551.6</td>
    </tr>
    <tr>
      <td>2.0</td>
      <td>446.598226</td>
      <td>326.3</td>
      <td>526.058036</td>
      <td>7585.0</td>
    </tr>
    <tr>
      <td>3.0</td>
      <td>425.790714</td>
      <td>309.6</td>
      <td>547.385352</td>
      <td>13101.5</td>
    </tr>
    <tr>
      <td>4.0</td>
      <td>405.047340</td>
      <td>302.0</td>
      <td>487.186744</td>
      <td>16894.9</td>
    </tr>
    <tr>
      <td>5.0</td>
      <td>415.213166</td>
      <td>298.2</td>
      <td>580.018040</td>
      <td>45609.0</td>
    </tr>
  </tbody>
</table>

<p>Below is the plot for the pivot table.</p>
<iframe src="assets/max.html" width="800" height="600" frameborder="0"></iframe>
<p>From this plot we can see that the <code class="language-plaintext highlighter-rouge">max</code> values were disproportionately higher than the other statistics. It skewed the visual representation, making it challenging to observe the trends and patterns of the other variables. To address this, the <code class="language-plaintext highlighter-rouge">max</code> variable was excluded in the next plot to focus on the <code class="language-plaintext highlighter-rouge">mean</code>, <code class="language-plaintext highlighter-rouge">median</code>, and <code class="language-plaintext highlighter-rouge">std</code> variables.</p>

<iframe src="assets/withoutmax.html" width="800" height="600" frameborder="0"></iframe>

<p>This exclusion allowed for a clearer and more meaningful comparison of these three measures across the rating scale from 1 to 5.  From the revised plot, an interesting finding emerged: while the <code class="language-plaintext highlighter-rouge">mean</code> and <code class="language-plaintext highlighter-rouge">median</code> values show a slight decrease as ratings increase from 1 to 4, they increase again for recipes with a rating of 5. This suggests that the highest-rated recipes do not necessarily have lower calorie content. Additionally, the <code class="language-plaintext highlighter-rouge">standard deviation</code> remains relatively consistent across ratings, indicating a similar variability in calorie content regardless of the rating.  This view of the data underscores that user preferences for recipes, as reflected by ratings, may not be solely influenced by calorie content.</p>

<hr />

<h2 id="assessment-of-missingness">Assessment of Missingness</h2>
<h3 id="nmar-analysis">NMAR Analysis</h3>
<p>In the NMAR scenario, the reason behind the missing data is related to the missing data itself. In the merged dataframe, the missingness type of the <code class="language-plaintext highlighter-rouge">description</code> column is probably NMAR. For example, users might not include a description for recipes that are simple or well-known because they think it’s self-explanatory, or they might omit descriptions for recipes that are family secrets or unique concoctions they prefer not to share. Both cases can make its missingness be NMAR.</p>

<h3 id="missingness-dependency">Missingness Dependency</h3>
<p>To better understand the missingness dependency, we will focus on the <code class="language-plaintext highlighter-rouge">rating</code> column of our merged DataFrame, we would like to investigate whether the missingness is dependent on other variables.  Specifically, we will conduct permutation tests on the <code class="language-plaintext highlighter-rouge">minutes</code> (time to prepare a recipe) and <code class="language-plaintext highlighter-rouge">n_ingredients</code> (number of ingredients in a recipe) columns to test for any dependency between these factors and the likelihood of a recipe being rated.</p>

<h4 id="rating-and-minutes">Rating and Minutes</h4>
<ul>
  <li>
    <p><strong>Null Hypothesis:</strong> The missingness of ratings is independent of the preparation time of the recipes. This means that the length of time to prepare a recipe does not affect whether a rating is missing or not.</p>
  </li>
  <li>
    <p><strong>Alternative Hypothesis</strong>: The missingness of ratings depends on the preparation time of the recipes. This implies that the time to prepare a recipe does affect the likelihood of a rating being missing.</p>
  </li>
</ul>

<p><strong>Test Statistic:</strong> The test statistic will be the absolute difference in mean minutes between the group of recipes with ratings and the group without ratings.</p>

<iframe src="assets/minutes.html" width="800" height="600" frameborder="0"></iframe>

<p>From the above plot, we notice that the distributions of minutes with ratings and minutes without ratings are quite similar, and we will conduct the permutation test to see the absolute difference mean within these two groups.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>missing
False    103.489569
True     154.941939
Name: minutes, dtype: float64
</code></pre></div></div>
<p>We calculated the observed difference to be 51.45 (rounded to 2 decimal places). Then we conduct the permutation test, shuffle the preparation time data 1000 times, re-split it into two groups and calculate the absolute mean. The plot below shows the empirical distribution of our permuted test statistics in 1000 permutations, the red line indicates the observed test statistics.</p>
<iframe src="assets/minutes_empirical.html" width="800" height="600" frameborder="0"></iframe>

<p>We calculate our p-value is 0.11. Since the calculated p-value of 0.11 is greater than the significance level α of 0.05, we fail to reject the null hypothesis. This suggests that there is not enough evidence to conclude that the missingness of ratings is related to the preparation time of the recipes.</p>

<p><strong>Therefore, we conclude that the missingness of ratings is independent of the preparation time based on our current analysis.</strong></p>

<h4 id="rating-and-n_ingredients-mar">Rating and N_ingredients (MAR)</h4>

<p>Similarly, we want to know whether there is a significant difference in the mean number of ingredients (n_ingredients) for recipes with the missingness of rating.</p>
<ul>
  <li>
    <p><strong>Null Hypothesis:</strong> The missingness of rating does not depend on the number of ingredients.</p>
  </li>
  <li>
    <p><strong>Alternative Hypothesis:</strong> The missingness of rating depends on the number of ingredients.</p>
  </li>
</ul>

<p><strong>Test Statistic:</strong> The test statistic will be the absolute difference in mean number of ingredients (n_ingredients) between the group of recipes with ratings and the group without ratings.</p>

<iframe src="assets/n_ingredients.html" width="800" height="600" frameborder="0"></iframe>

<p>From the histogram above, we notice their distributions of the number of ingredients with ratings and that of without ratings are very similar.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>missing
False    9.061196
True     9.221934
Name: n_ingredients, dtype: float64
</code></pre></div></div>

<p>We calculated the observed difference to be 0.16 (rounded to 2 decimal places). Then we conduct the permutation test, shuffle the number of ingredients data 1000 times, re-split it into two groups and calculate the abosulte mean.</p>

<iframe src="assets/n_ingredients_empirical.html" width="800" height="600" frameborder="0"></iframe>

<p>The above plot shows the empirical distribution of our test statistics in 1000 permutations, the red line indicates the observed test statistics (0.1607379066254797). <br />
From this plot and the result of our permutation test, we get a p-value of 0.0 which is significantly less than our significance level of 5%. Therefore, we reject the null hypothesis.</p>

<hr />

<h2 id="hypothesis-testing">Hypothesis Testing</h2>
<p>Back to our question: examine the relationship between recipe ratings and calorie content to see if higher rating corresponds to the higher calories.<br />
For this part, we define the recipe with a rating of 4 or 5 as “high”. The other with a rating of 1, 2, or 3 as “low” to calculate the mean of the calories content in these two levels.</p>

<h3 id="permutation-test">Permutation Test</h3>
<ul>
  <li><strong>Null Hypothesis:</strong> There is no difference in mean calorie content between recipes with high ratings (defined as a rating of 4 or 5) and recipes with low ratings (defined as a rating of 1, 2, or 3).</li>
  <li><strong>Alternative Hypothesis:</strong> There is a difference in mean calorie content, and specifically that recipes with high ratings have a different mean calorie content than recipes with low ratings.</li>
  <li><strong>Test Statistic:</strong> The test statistic is the absolute difference in the mean calorie counts between the <code class="language-plaintext highlighter-rouge">high</code> rating group (ratings of 4 and 5) and the <code class="language-plaintext highlighter-rouge">low</code> rating group (ratings of 1, 2, and 3).</li>
  <li><strong>Significance Level:</strong> To ensure the accuracy of our conclusion, we decided to use a significance level of 5% as our significance level.</li>
</ul>

<p>Below is the table that contains some columns from our dataset. We add one more column <code class="language-plaintext highlighter-rouge">high_rating</code> to our dataset, which is <code class="language-plaintext highlighter-rouge">High</code> if the rating of the recipe is 4 or 5 and <code class="language-plaintext highlighter-rouge">Low</code> if the rating is 1, 2 or 3.</p>

<table>
  <thead>
    <tr>
      <th>name</th>
      <th>id</th>
      <th>calories (#)</th>
      <th>rating</th>
      <th>high_rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1 brownies in the world best ever</td>
      <td>333281</td>
      <td>138.4</td>
      <td>4.0</td>
      <td>High</td>
    </tr>
    <tr>
      <td>1 in canada chocolate chip cookies</td>
      <td>453467</td>
      <td>595.1</td>
      <td>5.0</td>
      <td>High</td>
    </tr>
    <tr>
      <td>412 broccoli casserole</td>
      <td>306168</td>
      <td>194.8</td>
      <td>5.0</td>
      <td>High</td>
    </tr>
    <tr>
      <td>412 broccoli casserole</td>
      <td>306168</td>
      <td>194.8</td>
      <td>5.0</td>
      <td>High</td>
    </tr>
    <tr>
      <td>412 broccoli casserole</td>
      <td>306168</td>
      <td>194.8</td>
      <td>5.0</td>
      <td>High</td>
    </tr>
  </tbody>
</table>

<p>From the plot below, we notice that the distributions of different ratings and calories content are quite similar, and we will conduct the permutation test to see the absolute difference mean within these two groups.</p>

<iframe src="assets/per_calories.html" width="800" height="600" frameborder="0"></iframe>

<p>We conduct the permutation test, shuffle the <code class="language-plaintext highlighter-rouge">high_rating</code> column 1000 times, re-split it into two groups and calculate the absolute mean. The plot below shows the empirical distribution of our permuted test statistics in 1000 permutations, the red line indicates the observed test statistics which is 52.51 (rounded to 2 decimal places).</p>
<iframe src="assets/calories_empirical.html" width="800" height="600" frameborder="0"></iframe>
<p>From the plot above and the result of our permutation test, we get a p-value of 0.0 which is significantly less than our significance level of 5%. Therefore, we reject the null hypothesis.</p>

<hr />

<h2 id="conclusion">Conclusion</h2>
<p>The permutation test shows a statistically significant difference in the mean calorie content between recipes with high ratings (ratings of 4 and 5) and those with low ratings (ratings of 1, 2, and 3). This result suggests that the calorie content of a recipe is indeed associated with its user rating. It indicates that recipes with higher ratings tend to have different calorie content compared to those with lower ratings. This finding highlights a potential preference or trend among users related to the calorie content of highly rated recipes.</p>

<hr />

<h2 id="recipes-rating-prediction">Recipes Rating Prediction</h2>

<h2 id="framing-the-problem">Framing the Problem</h2>
<p>In the culinary world, the balance between taste and health is a subject of much interest and debate. Meals are a critical factor in this balance, directly affecting an individual’s health and well-being. In this project, we aim to predict the rating of a recipe based on various features, like average rating of a recipe, number of ratings for each recipe, users’ average rating for recipes, and minutes to prepare a recipe. Therefore, we will build a regression model to fit our data to predict the rating for unseen recipes.</p>

<h4 id="response-variable"><strong>Response Variable</strong></h4>
<p>We chose <code class="language-plaintext highlighter-rouge">rating</code> as the response variable, which has five different classes from star one to star five. Understanding the rating of a recipe helps people to regulate their meals for better health.</p>

<h4 id="evaluation-metric"><strong>Evaluation Metric</strong></h4>
<p>To evaluate the model’s performance, we will use metrics such as <strong>RMSE</strong>. That’s because there are lots of outliers in our features, like lots of time to prepare recipes. So we choose RMSE because it is sensitive to outliers. It will give a higher error value, signaling that these points are not being predicted accurately.</p>

<hr />

<h2 id="baseline-model">Baseline Model</h2>

<h3 id="model-description">Model Description</h3>
<p>In our baseline model, we intend to predict whether the <code class="language-plaintext highlighter-rouge">rating</code> is based on the average rating of the recipe and total minutes needed to prepare for a recipe. We will use <code class="language-plaintext highlighter-rouge">recipe_average_rating</code> and <code class="language-plaintext highlighter-rouge">log_minute</code> as features of our baseline Linear Regression model.</p>

<h3 id="feature-transformations">Feature Transformations</h3>
<p>For this baseline model, we did not have any categorical features, so we did not need to use OneHotEncoder() or any other categorical transformations.</p>

<p><code class="language-plaintext highlighter-rouge">recipe_average_rating</code>: This is an ordinary feature. From the scatter plot, we can see that there is some relationship between the average rating and the rating, which is that higher average ratings tend to have higher ratings. We just keep it as the raw integer value for simplicity.</p>

<iframe src="assets/fig_average_rating.html" width="800" height="600" frameborder="0"></iframe>

<p><code class="language-plaintext highlighter-rouge">minutes</code>: This is a nominal feature. First we plot the box plot below to see the relationship between minutes. We found that there are lots of recipes that have a long preparation time, which represents the outliers within each rating level. So we decided to use log transformation to transform minutes by log to make it more suitable for prediction. From the new scatter plot, we can see that the longest preparation time is around 15.</p>

<iframe src="assets/fig_minutes_rating.html" width="800" height="600" frameborder="0"></iframe>
<iframe src="assets/fig_log_min.html" width="800" height="600" frameborder="0"></iframe>

<h3 id="performance">Performance</h3>
<p>Our model achieved a training RMSE of 0.3715 and a testing RMSE of 0.5147. This level of RMSE indicates that the model has a reasonably good predictive capability. That is, if a recipe has a high average rating, it is more likely to receive similarly high ratings from new reviewers, keeping its high score. Our model’s performance corroborates this theory, following the tendency of recipes with higher ratings to maintain higher future ratings.</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Train RMSE</th>
      <th>Test RMSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>‘RMSE’</td>
      <td>0.371539447765363</td>
      <td>0.5147232717849082</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="final-model">Final Model</h2>

<h3 id="description"><strong>Description</strong></h3>

<p><code class="language-plaintext highlighter-rouge">recipe_num_ratings</code>: For the number of ratings for each recipe, we want to study whether a recipe with a higher number of ratings possibly tends to receive higher ratings from people.</p>

<p><code class="language-plaintext highlighter-rouge">user_average_rating</code>: For the user’s average rating, we want to check if a person tends to give a higher rating just because he habitually gives high scores.</p>

<h3 id="performance-1"><strong>Performance</strong></h3>

<p>In crafting our predictive model, we incorporated two additional features: <code class="language-plaintext highlighter-rouge">user_average_rating</code> and <code class="language-plaintext highlighter-rouge">recipe_num_ratings</code>. The inclusion of <code class="language-plaintext highlighter-rouge">user_average_rating</code> is predicated on the assumption that individual rating behaviors are consistent across multiple reviews. Thus, a user who tends to give higher ratings might similarly rate new recipes they encounter with high ratings. This feature captures the individual bias of users, which is fundamental to understanding the variability in recipe ratings.</p>

<p>The second feature, <code class="language-plaintext highlighter-rouge">recipe_num_ratings</code>, is grounded in the theory of wisdom of the crowds, which states that the information collection in groups results in decisions that are often better than the decisions made by any single member of the group. This implies that recipes with a large number of ratings are likely to have a more reliable rating, indicating that a large number of ratings on one recipe tends to have higher ratings than those with a smaller number of ratings.</p>

<p>For our predictive modeling, we also tried the Decision Tree Regressor model, a non-linear model that is well-suited for capturing complex patterns in data which linear models might miss. Decision trees are particularly adept at modeling interactions between different features, which we hypothesized would be present in our dataset.</p>

<p>Then we fine-tuned our model using GridSearch to optimize the hyperparameters <code class="language-plaintext highlighter-rouge">max_depth</code> and <code class="language-plaintext highlighter-rouge">min_samples_split</code>. This approach systematically works through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance. We evaluated 70 different combinations, seeking to strike a balance between a model that is complex enough to learn the data well, but not so complex that it overfits. Finally, we got the best performance with the <code class="language-plaintext highlighter-rouge">max_depth</code> of 10 and the <code class="language-plaintext highlighter-rouge">min_samples_split</code> of 100.</p>

<p>Next, we calculated and compared the <strong>RMSE</strong> of the testing sets for each model as the table shown below. We found the DecisionTreeRegressor with the best hyperparameter has the lowest RMSE, so we chose this to be our final model.</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Test RMSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>‘RMSE for regression with two features’</td>
      <td>0.5147232717849082</td>
    </tr>
    <tr>
      <td>‘RMSE for regression with three features’</td>
      <td>0.3758448690196555</td>
    </tr>
    <tr>
      <td>‘RMSE for regression with four features’</td>
      <td>0.3758027040111092</td>
    </tr>
    <tr>
      <td>‘RMSE for the DecisionTreeRegressor’</td>
      <td>0.43897293968980095</td>
    </tr>
    <tr>
      <td>‘RMSE for the DecisionTreeRegressor with the best hyperparameter’</td>
      <td>0.3215798723839845</td>
    </tr>
  </tbody>
</table>

<iframe src="assets/fig.html" width="800" height="600" frameborder="0"></iframe>
<p>As we can see from the plot below, our final model’s performance was an improvement over our baseline model, which we can infer our baseline model was a simpler and a basic linear regression model without these additional features or a non-tuned decision tree. The final Decision Tree Regressor with optimal hyperparameters yielded the lowest RMSE on the testing set, indicating that it was the most accurate at predicting recipe ratings. The reduction in RMSE from the baseline to the final model signifies an enhancement in predictive accuracy, likely due to the model’s increased complexity and ability to capture more subtle patterns within the data.</p>

<hr />

<h2 id="fairness-analysis">Fairness Analysis</h2>

<p>In our pursuit of developing a fair and equitable predictive model for recipe ratings, we pose a critical question: Does our model demonstrate differential performance for recipes with perfect 5-star ratings as opposed to those rated 4 stars or below?
For this question, we divided our recipes into two different groups based on its rating.</p>

<p><strong>GroupX:</strong> Recipes with 5-star ratings.</p>

<p><strong>GroupY:</strong> Recipes with ratings of 4 stars or below.</p>

<h3 id="permutation-test-1">Permutation Test</h3>
<ul>
  <li><strong>Null Hypothesis:</strong> Our model is fair. Its prediction of recipes with 5 stars and the recipes with four or less stars are roughly the same, and any differences are likely due to chance.</li>
  <li><strong>Alternative Hypothesis:</strong> Our model is not fair. Its prediction of recipes with 5 stars is different from recipes with 4 or less stars.</li>
  <li><strong>Test Statistic:</strong> The test statistic is the absolute difference in the RMSE between these two groups: high rating group (ratings of 5) and the low rating group (ratings below 5).</li>
  <li><strong>Significance Level:</strong> To ensure the accuracy of our conclusion, we decided to use a significance level of 5% as our significance level.</li>
</ul>

<p>We conduct the permutation test, shuffle the recipes with 5 stars column 1000 times, re-split it into two groups and calculate the absolute differece in RMSE. The plot below shows the empirical distribution of our permuted test statistics in 1000 permutations, the red line indicates the observed test statistics which is 0.2197 (rounded to 4 decimal places) which is our RMSE.</p>

<iframe src="assets/fig_calories_empirical.html" width="800" height="600" frameborder="0"></iframe>

<p>We calculate our p-value is 0. Since the calculated p-value of 0 is smaller than the significance level α of 0.05, we reject the null hypothesis. We cannot say that our model is fair based on our RMSE fairness analysis alone.</p>

<p>Therefore, we conclude that our model is not fair. Its prediction of recipes with 5 stars is different from recipes with 4 or less stars.</p>

<hr />


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/VickyShu/Recipes-and-Ratings-Research-Project">Recipes-and-Ratings-Research-Project</a> is maintained by <a href="https://github.com/VickyShu">VickyShu</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
